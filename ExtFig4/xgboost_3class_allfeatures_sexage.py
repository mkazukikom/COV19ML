# -*- coding: utf-8 -*-
"""xgboost_3class_allfeatures_sexage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z_0AfuxajDkC2FU80HRUqwzVQrUtO9v7
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.manifold import TSNE
from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, log_loss, mean_squared_error, confusion_matrix
from sklearn.metrics import recall_score, precision_score, f1_score
import xgboost as xgb
from tqdm import tqdm
#import umap

np.random.seed(51)

from google.colab import drive
drive.mount('/content/drive')

dir_name = '/content/drive/MyDrive/COV19ML_share/data_20250201/'
aav_data = pd.read_csv(dir_name+'AAV_data_3.csv')
ad_data = pd.read_csv(dir_name+'AD_data_3.csv')
covid_data = pd.read_csv(dir_name+'COVID_data_3.csv')
hc_data = pd.read_csv(dir_name+'HC_data_3.csv')
sle_data = pd.read_csv(dir_name+'SLE_data_3.csv')
ssc_data = pd.read_csv(dir_name+'SSc_data_3.csv')

print(aav_data.shape, ad_data.shape, covid_data.shape,
      hc_data.shape, sle_data.shape, ssc_data.shape)

data = pd.concat([aav_data, ad_data, covid_data, hc_data, sle_data, ssc_data])
data.CLASS.value_counts()

# prompt: in the column sex, change F to 1 and M to 0.

# Assuming 'data' DataFrame is already loaded as shown in the provided code.

# Replace 'F' with 1 and 'M' with 0 in the 'sex' column.
data['sex'] = data['sex'].replace({'F': 1, 'M': 0})

y_covid = data.COVID
y_covid= y_covid.to_numpy()
y_all = data.CLASS.to_numpy()

X = data.drop(columns=['ID','CLASS','COVID'])
#X /= X.max(axis=0)
n_data, n_features = X.shape
feature_names = X.columns.values
for i in range(len(y_covid)):
    if y_all[i]=='COVID_moderate' or y_all[i]=='COVID_severe':
        y_covid[i] = 2
print(X.shape, len(y_covid[y_covid==0]), len(y_covid[y_covid==1]), len(y_covid[y_covid==2]) )
n_class = len(np.unique(y_covid))

print(y_covid)

num_round = 40
lr = 0.05
acc_list_all_tr = []
acc_list_all_te = []
precision_list_all_tr = []
precision_list_all_te = []
recall_list_all_tr = []
recall_list_all_te = []
f1score_list_all_tr = []
f1score_list_all_te = []
table_list_all_tr = []
table_list_all_te = []
selected_feature_list = []
imp_list = []
n_fold = 10
X_np = X.to_numpy()
df_imp_all = pd.DataFrame({"feature_importance": np.zeros(len(feature_names))}, index=feature_names)
skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=0)
for (tr, te) in skf.split(X_np, y_all):   # 全クラスのデータを均一に分割
    X_tr, X_te, y_tr, y_te = X_np[tr], X_np[te], y_covid[tr], y_covid[te]
    scaler = StandardScaler()
    X_tr = scaler.fit_transform(X_tr)
    X_te = scaler.transform(X_te)
    dtrain_all = xgb.DMatrix(pd.DataFrame(X_tr, columns=feature_names), label=y_tr) #, feature_names=feature_names.tolist())
    dtest_all = xgb.DMatrix(pd.DataFrame(X_te, columns=feature_names), label=y_te)
    param = {'objective': 'multi:softprob', 'nthread': 1, 'num_class': len(np.unique(y_covid)), 'eta': lr, 'subsample': 0.5}
    param['eval_metric'] = ['merror', 'mlogloss']
    evallist_all = [(dtrain_all, 'train')] # , (dtest, 'eval')]
    bst = xgb.train(param, dtrain_all, num_round, evallist_all) #, early_stopping_rounds=10)
    pred_tr = bst.predict(dtrain_all) #, iteration_range=(0, bst.best_iteration + 1))
    df_imp_each = pd.DataFrame({"feature_importance": np.zeros(len(feature_names))}, index=feature_names)
    for k, v in zip(bst.get_fscore().keys(), bst.get_fscore().values()):
        df_imp_all.at[k,"feature_importance"] += v
        df_imp_each.at[k,"feature_importance"] += v
    ### feature selection ###
    df_imp_each = df_imp_each.sort_values(by="feature_importance", ascending=False)
    imp_list.append(df_imp_each)
    #
    pred_te = bst.predict(dtest_all) #, iteration_range=(0, bst.best_iteration + 1))
    ###
    pred_tr = pred_tr.argmax(axis=1)
    pred_te = pred_te.argmax(axis=1)
    acc_tr = accuracy_score(y_tr, pred_tr)
    acc_te = accuracy_score(y_te, pred_te)
    precision_tr = precision_score(y_tr,pred_tr,average='macro')
    precision_te = precision_score(y_te,pred_te,average='macro')
    recall_tr = recall_score(y_tr,pred_tr,average='macro')
    recall_te = recall_score(y_te,pred_te,average='macro')
    f1score_tr = f1_score(y_tr,pred_tr,average='macro')
    f1score_te = f1_score(y_te,pred_te,average='macro')
    table_tr = confusion_matrix(y_tr, pred_tr, labels=[i for i in range(n_class)])
    table_tr = pd.DataFrame(table_tr, index=["label"+str(i) for i in range(n_class)], columns=["pred"+str(i) for i in range(n_class)]).T
    table_te = confusion_matrix(y_te, pred_te, labels=[i for i in range(n_class)])
    table_te = pd.DataFrame(table_te, index=["label"+str(i) for i in range(n_class)], columns=["pred"+str(i) for i in range(n_class)]).T
    acc_list_all_tr.append(acc_tr)
    acc_list_all_te.append(acc_te)
    precision_list_all_tr.append(precision_tr)
    precision_list_all_te.append(precision_te)
    recall_list_all_tr.append(recall_tr)
    recall_list_all_te.append(recall_te)
    f1score_list_all_tr.append(f1score_tr)
    f1score_list_all_te.append(f1score_te)
    table_list_all_tr.append(table_tr)
    table_list_all_te.append(table_te)
df_imp_all = df_imp_all.sort_values(by="feature_importance", ascending=False)
df_imp_all['feature_importance'] /= n_fold
print(f"tr mean: {np.mean(acc_list_all_tr)}, tr stddev: {np.std(acc_list_all_tr)}, te mean: {np.mean(acc_list_all_te)}, te stddev: {np.std(acc_list_all_te)}")

for i in range(n_fold):
    table_list_all_tr[i].index = "train_"+table_list_all_tr[i].index+"_cv"+str(i)
    table_list_all_te[i].index = "valid_"+table_list_all_te[i].index+"_cv"+str(i)

# label 1 is positive

for i in range(n_fold):
    print(table_list_all_tr[i].to_markdown())
    print(f'acc:{acc_list_all_tr[i]:.5f}, recall:{recall_list_all_tr[i]:.5f}, precision:{precision_list_all_tr[i]:.5f}, fvalue:{f1score_list_all_tr[i]:.5f}')

for i in range(n_fold):
    print(table_list_all_te[i].to_markdown())
    print(f'acc:{acc_list_all_te[i]:.5f}, recall:{recall_list_all_te[i]:.5f}, precision:{precision_list_all_te[i]:.5f}, fvalue:{f1score_list_all_te[i]:.5f}')

df_all_acc = pd.DataFrame([np.mean(acc_list_all_tr), np.std(acc_list_all_tr), np.mean(acc_list_all_te), np.std(acc_list_all_te)]).T
df_all_recall = pd.DataFrame([np.mean(recall_list_all_tr), np.std(recall_list_all_tr), np.mean(recall_list_all_te), np.std(recall_list_all_te)]).T
df_all_precision = pd.DataFrame([np.mean(precision_list_all_tr), np.std(precision_list_all_tr), np.mean(precision_list_all_te), np.std(precision_list_all_te)]).T
df_all_fvalue = pd.DataFrame([np.mean(f1score_list_all_tr), np.std(f1score_list_all_tr), np.mean(f1score_list_all_te), np.std(f1score_list_all_te)]).T

df = pd.concat([df_all_acc,df_all_recall,df_all_precision,df_all_fvalue], axis=0)
df.columns = ["train mean", "train stddev", "valid mean", "valid stddev"]
df.index = ["accuracy","recall","precision","fvalue"]
print(df.to_markdown())

tmp_imp = pd.concat(imp_list, axis=1)
tmp_imp_stat = pd.concat([tmp_imp.T.mean(), tmp_imp.T.std()],axis=1)
tmp_imp_stat.columns=["mean","std"]
tmp_imp_stat.sort_values(by="mean", ascending=False,inplace=True)
tmp_imp_stat.to_csv("xgboost_3class_feature_importance.csv", index=True)
print(tmp_imp_stat.iloc()[:30,:].to_markdown())

imp_dict = {}
for k, v in zip(df_imp_all.index, df_imp_all.feature_importance):
    if v>0:
        imp_dict[k] = v
xgb.plot_importance(imp_dict, xlabel="feature importance", max_num_features=10)

'''
top5 同一スコアは含む
eta 0.05, 40 steps, subsample 1
|           |   train mean |   train stddev |   valid mean |   valid stddev |
|:----------|-------------:|---------------:|-------------:|---------------:|
| accuracy  |            1 |              0 |     0.805911 |      0.0536279 |
| recall    |            1 |              0 |     0.514668 |      0.105274  |
| precision |            1 |              0 |     0.546499 |      0.174243  |
| fvalue    |            1 |              0 |     0.519476 |      0.128264  |
eta 0.05, 40 steps, subsample 0.75
|           |   train mean |   train stddev |   valid mean |   valid stddev |
|:----------|-------------:|---------------:|-------------:|---------------:|
| accuracy  |            1 |              0 |     0.82697  |      0.0390231 |
| recall    |            1 |              0 |     0.53474  |      0.0550871 |
| precision |            1 |              0 |     0.495678 |      0.0523824 |
| fvalue    |            1 |              0 |     0.512303 |      0.0546952 |
eta 0.05, 40 steps, subsample 0.5
|           |   train mean |   train stddev |   valid mean |   valid stddev |
|:----------|-------------:|---------------:|-------------:|---------------:|
| accuracy  |     0.972227 |      0.0050565 |     0.837315 |      0.0499868 |
| recall    |     0.9138   |      0.0159232 |     0.534206 |      0.0589597 |
| precision |     0.988005 |      0.0020801 |     0.509637 |      0.0641203 |
| fvalue    |     0.947047 |      0.0105257 |     0.519397 |      0.0602725 |
eta 0.05, 40 steps, subsample 0.25
|           |   train mean |   train stddev |   valid mean |   valid stddev |
|:----------|-------------:|---------------:|-------------:|---------------:|
| accuracy  |     0.913539 |     0.00862593 |     0.816502 |      0.042743  |
| recall    |     0.753231 |     0.0246971  |     0.495469 |      0.0592251 |
| precision |     0.943149 |     0.0152955  |     0.521802 |      0.0802405 |
| fvalue    |     0.818599 |     0.024392   |     0.494865 |      0.0634191 |
eta 0.05, 40 steps, subsample 0.125
|           |   train mean |   train stddev |   valid mean |   valid stddev |
|:----------|-------------:|---------------:|-------------:|---------------:|
| accuracy  |     0.820797 |      0.0169339 |     0.746059 |      0.0296836 |
| recall    |     0.485536 |      0.0383429 |     0.355238 |      0.0382918 |
| precision |     0.704923 |      0.161117  |     0.334413 |      0.141227  |
| fvalue    |     0.509935 |      0.0474941 |     0.322015 |      0.0591998 |

eta 0.025, 40 steps, subsample 0.5
|           |   train mean |   train stddev |   valid mean |   valid stddev |
|:----------|-------------:|---------------:|-------------:|---------------:|
| accuracy  |     0.951101 |     0.00783345 |     0.823276 |      0.0495932 |
| recall    |     0.858224 |     0.0230428  |     0.522922 |      0.0664786 |
| precision |     0.978772 |     0.00380296 |     0.491634 |      0.0700263 |
| fvalue    |     0.908622 |     0.0166482  |     0.503587 |      0.0671793 |
'''