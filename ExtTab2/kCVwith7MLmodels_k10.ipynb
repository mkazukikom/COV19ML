print('')
print('■ The k-fold Cross Validation with different Machine Learning models')
print('')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
import pickle
import os
from collections import defaultdict
import warnings

from sklearn.model_selection import KFold, cross_val_score, cross_validate
from sklearn.metrics import (
    roc_auc_score,
    r2_score,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    matthews_corrcoef
)

warnings.simplefilter(action='ignore', category=UserWarning)

# データの読み込み。 path_inは分析対象のCSVファイルのGoogle Drive上のディレクトリ
df = pd.read_csv(str(path_in))

# データの大きさ
print('◆ 行と列の数')
print(df.shape)

# kの設定
n_samples = len(df)
print(f'The sample size of dataset: {n_samples}')

min_test_samples = 50
k = max(2, np.floor(n_samples / min_test_samples).astype(int))
max_k = 10
k = min(k, max_k)
# k-foldのkをマニュアルで決める場合は次の行を加える
k = 10

print(f"Chosen value of k for k-fold cross-validation: {k}")
print('')

# 定数の設定
random_state = 42
n_trialsA = 100
n_trialsB = 50
n_trialsC = 10

# Numpyのデータの作成
x = df.iloc[:, :-1].values
t = df.iloc[:, -1].values

# 目的変数の分布の表示
print('◆ 目的変数の分布')
sns.displot(df.iloc[:,-1].dropna())
print('陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(t>0)/len(t)), 5)) + ' %')
print('')
plt.show()

# 出力ファイル
from datetime import datetime
current_time = datetime.now()
formatted_time = current_time.strftime('%Y%m%d%H%M%S')

filename0 = os.path.basename(path_in)
filename = os.path.splitext(filename0)[0]
filepath1 = path_out + '/ResultsOf' + filename + 'withoutNB' + str(formatted_time) + '.xlsx'
filepath2 = path_out + '/ResultsOf' + filename + 'withNB' + str(formatted_time) + '.xlsx'
filepath3 = path_out + '/ResultsOf' + filename + 'wihtoutkNN&NB' + str(formatted_time) + '.xlsx'

print('◆ 計算結果の出力先')
print('1. Naive Bayes 以外の結果')
print(filepath1)
print('2. Naive Bayes も含めた結果')
print(filepath2)
print('3. Naive Bayes も k-Nearest Neighbours も含めない結果')
print(filepath3)
print('')
print('')

# MCCを計算する関数
def compute_mcc(y_true, y_pred):
    return matthews_corrcoef(y_true, y_pred)

###############################################################################
# Helper: CV結果をまとめて DataFrame を作る関数
#  (各モデルの関数で共通利用: metricsリストを受け取って mean/std を計算しDataFrame返却)
###############################################################################

def make_result_df(metrics, model_name):
    """
    metrics: dict 形式 (各キーに Foldごとの値のリストが入っている想定)
    model_name: str
    """
    data_row = {}

    # 指標ごとにループを回してデータを整理
    for metric_name, values in metrics.items():
        # 1. 各Foldの値を格納 (Fold 1, Fold 2...)
        for i, v in enumerate(values):
            data_row[f'{metric_name}_fold{i+1}'] = v

        # 2. 統計値（Mean, Std）を計算して格納
        data_row[f'{metric_name}_mean'] = np.mean(values)
        data_row[f'{metric_name}_std'] = np.std(values)

    # DataFrameの作成
    df_result = pd.DataFrame([data_row], index=[model_name])

    # 表示用（コンソール出力）
    print(f'■ {model_name}')
    for m in metrics.keys():
        m_mean = data_row[f'{m}_mean']
        m_std = data_row[f'{m}_std']
        print(f'Mean {m.upper()}: {m_mean:.4f} ± {m_std:.4f}')
    print('')

    return df_result

##########################################
# simple Linear Regression
##########################################
def LinearKFold(k=k):
    from sklearn.linear_model import LinearRegression

    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    kf = KFold(n_splits=k, shuffle=True, random_state=42)
    lr = LinearRegression()

    # 指標を格納するリスト
    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        lr.fit(X_train, y_train)
        predictions = lr.predict(X_test)

        # 0.5を閾値とした2値化
        predictions_round = [1 if p >= 0.5 else 0 for p in predictions]

        auc = roc_auc_score(y_test, predictions)
        acc = accuracy_score(y_test, predictions_round)
        prec = precision_score(y_test, predictions_round, zero_division=0)
        rec = recall_score(y_test, predictions_round)
        f1 = f1_score(y_test, predictions_round)
        mcc = compute_mcc(y_test, predictions_round)

        metrics['auc'].append(auc)
        metrics['acc'].append(acc)
        metrics['prec'].append(prec)
        metrics['rec'].append(rec)
        metrics['f1'].append(f1)
        metrics['mcc'].append(mcc)

    # フルデータで学習したモデルを保存 (Coefficients)
    model_full = LinearRegression()
    model_full.fit(X, y)
    feature_importances = model_full.coef_
    column_names = df.columns[:-1]
    feature_importances_df = pd.DataFrame({'Feature': column_names, 'Importance': feature_importances})
    feature_importances_df['Abs_Importance'] = feature_importances_df['Importance'].abs()
    feature_importances_df = feature_importances_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)

    os.makedirs(path_out, exist_ok=True)
    excel_filename = os.path.join(path_out, 'feature_importances_linear.xlsx')
    feature_importances_df.to_excel(excel_filename, index=False)

    # 上位10特徴を可視化
    importance_sorted_idx = np.argsort(np.abs(feature_importances))[::-1]
    top_idxs = importance_sorted_idx[:10]

    # 結果表示・DataFrame生成
    res2 = make_result_df(metrics, 'Linear Regression')

    plt.figure(figsize=(10, 8))
    plt.barh(range(len(top_idxs)), feature_importances[top_idxs], align='center')
    plt.yticks(range(len(top_idxs)), [column_names[i] for i in top_idxs])
    plt.xlabel('Feature Importance')
    plt.title('Top 10 Feature Importances from Linear Regression Model')
    plt.gca().invert_yaxis()
    plt.show()

    # モデルを保存
    os.makedirs(path_model, exist_ok=True)
    model_filename = os.path.join(path_model, 'kFCV_linear_model.pkl')
    with open(model_filename, 'wb') as file:
        pickle.dump(model_full, file)

    return res2

##########################################
# Lasso Regression
##########################################
def LassoKFold(alpha_value=1.0, k=k):
    from sklearn.linear_model import Lasso

    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)
    lasso = Lasso(alpha=alpha_value)

    # 指標リスト
    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }

    feature_importance = np.zeros((X.shape[1],))

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        lasso.fit(X_train, y_train)
        predictions = lasso.predict(X_test)

        feature_importance += np.abs(lasso.coef_)

        predictions_round = [1 if p >= 0.5 else 0 for p in predictions]

        auc = roc_auc_score(y_test, predictions)
        acc = accuracy_score(y_test, predictions_round)
        prec = precision_score(y_test, predictions_round, zero_division=0)
        rec = recall_score(y_test, predictions_round)
        f1 = f1_score(y_test, predictions_round)
        mcc = compute_mcc(y_test, predictions_round)

        metrics['auc'].append(auc)
        metrics['acc'].append(acc)
        metrics['prec'].append(prec)
        metrics['rec'].append(rec)
        metrics['f1'].append(f1)
        metrics['mcc'].append(mcc)

    feature_importance /= k
    feature_names = df.columns[:-1]
    feature_importance_series = pd.Series(feature_importance, index=feature_names)
    sorted_importance = feature_importance_series.sort_values(ascending=False)[:10]

    # 結果表示・DataFrame
    res2 = make_result_df(metrics, f'Lasso Regression (α={alpha_value:.4f})')

    # グラフ
    plt.figure(figsize=(10, 8))
    plt.title('Top 10 Feature Importances from k-foldCV of Lasso Regression')
    sorted_importance.plot(kind='barh')
    plt.gca().invert_yaxis()
    plt.xlabel('Average Absolute Coefficient')
    plt.show()
    print('')

    # モデルをフルデータで再学習 & 保存
    model_full = Lasso(alpha=alpha_value)
    model_full.fit(X, y)
    os.makedirs(path_model, exist_ok=True)
    model_filename = os.path.join(path_model, 'kFCV_lasso_model.pkl')
    with open(model_filename, 'wb') as file:
        pickle.dump(model_full, file)

    return res2

##########################################
# Ridge Regression
##########################################
def RidgeKFold(alpha_value=1.0, k=k):
    from sklearn.linear_model import Ridge

    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)
    ridge = Ridge(alpha=alpha_value)

    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }

    feature_importances = np.zeros(X.shape[1])

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        ridge.fit(X_train, y_train)
        predictions = ridge.predict(X_test)

        feature_importances += np.abs(ridge.coef_)

        predictions_round = [1 if p >= 0.5 else 0 for p in predictions]

        auc = roc_auc_score(y_test, predictions)
        acc = accuracy_score(y_test, predictions_round)
        prec = precision_score(y_test, predictions_round, zero_division=0)
        rec = recall_score(y_test, predictions_round)
        f1 = f1_score(y_test, predictions_round)
        mcc = compute_mcc(y_test, predictions_round)

        metrics['auc'].append(auc)
        metrics['acc'].append(acc)
        metrics['prec'].append(prec)
        metrics['rec'].append(rec)
        metrics['f1'].append(f1)
        metrics['mcc'].append(mcc)

    # 平均的な特徴重要度(係数の絶対値)
    feature_importances /= k
    feature_importances = pd.Series(feature_importances, index=df.columns[:-1])
    top10_features = feature_importances.nlargest(10)

    # 結果表示・DataFrame
    res2 = make_result_df(metrics, f'Ridge Regression (α={alpha_value:.4f})')

    plt.figure(figsize=(10, 8))
    top10_features.plot(kind='barh').invert_yaxis()
    plt.title('Top 10 Feature Importances from k-foldCV of Ridge Regression')
    plt.xlabel('Mean Absolute Coefficient')
    plt.show()

    model_full = Ridge(alpha=alpha_value)
    model_full.fit(X, y)

    os.makedirs(path_model, exist_ok=True)
    model_filename = os.path.join(path_model, 'kFCV_ridge_model.pkl')
    with open(model_filename, 'wb') as file:
        pickle.dump(model_full, file)

    return res2

##########################################
# simple Ridge Regression (used in optuna)
##########################################
def simpleRidgeKFold(alpha_value, k=k):
    from sklearn.linear_model import Ridge
    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)
    ridge = Ridge(alpha=alpha_value)

    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        ridge.fit(X_train, y_train)
        predictions = ridge.predict(X_test)

        predictions_round = [1 if p >= 0.5 else 0 for p in predictions]

        auc = roc_auc_score(y_test, predictions)
        acc = accuracy_score(y_test, predictions_round)
        prec = precision_score(y_test, predictions_round, zero_division=0)
        rec = recall_score(y_test, predictions_round)
        f1 = f1_score(y_test, predictions_round)
        mcc = compute_mcc(y_test, predictions_round)

        metrics['auc'].append(auc)
        metrics['acc'].append(acc)
        metrics['prec'].append(prec)
        metrics['rec'].append(rec)
        metrics['f1'].append(f1)
        metrics['mcc'].append(mcc)

    res2 = make_result_df(metrics, f'Ridge Regression (α={alpha_value:.4f})')
    return res2

##########################################
# Ridge Optimized with Optuna
##########################################
def objective_ridge(trial, X, y, k=k):
    from sklearn.linear_model import Ridge
    alpha = trial.suggest_float('alpha', 0.0001, 10.0, log=True)

    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)
    mse_scores = []

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        model = Ridge(alpha=alpha, random_state=random_state)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        mse_scores.append(mse)

    return np.mean(mse_scores)

def RidgeKFoldOptuna(k=k):
    from sklearn.linear_model import Ridge
    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    study = optuna.create_study(direction='minimize')
    optuna.logging.disable_default_handler()
    study.optimize(lambda trial: objective_ridge(trial, X, y, k), n_trials=n_trialsA)

    best_alpha = study.best_trial.params['alpha']

    print('')
    print('◆ Hypterparameter Optimization for Ridge with Optuna')
    print(f'Best trial for minimizing MSE:')
    print(f'  Value: {study.best_trial.value}')
    print(f'  Params: ')
    for key, value in study.best_trial.params.items():
        print(f'    {key}: {value}')
    print('')

    best_model = Ridge(alpha=best_alpha, random_state=random_state)
    best_model.fit(X, y)

    res = simpleRidgeKFold(best_alpha, k=k)

    feature_names = df.columns[:-1]
    feature_importance = np.abs(best_model.coef_)
    feature_importance_series = pd.Series(feature_importance, index=feature_names)
    sorted_importance = feature_importance_series.sort_values(ascending=False)[:10]

    plt.figure(figsize=(10, 8))
    plt.title('Top 10 Feature Importances from Best Ridge Model optimized with Optuna')
    sorted_importance.plot(kind='barh')
    plt.gca().invert_yaxis()
    plt.xlabel('Absolute Coefficient')
    plt.show()
    print('')

    os.makedirs(path_model, exist_ok=True)
    model_filename = os.path.join(path_model, 'kFCV_optuna_ridge_model.pkl')
    with open(model_filename, 'wb') as file:
        pickle.dump(best_model, file)

    return res

##########################################
# Logistic Normalized
##########################################
def LogisticKFoldNormalized(k=k):
    from sklearn.linear_model import LogisticRegression
    from sklearn.preprocessing import MinMaxScaler

    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)

    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)

    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }

    feature_importances = np.zeros((df.shape[1] - 1,))

    for train_index, test_index in kf.split(X_scaled):
        X_train, X_test = X_scaled[train_index], X_scaled[test_index]
        y_train, y_test = y[train_index], y[test_index]

        model = LogisticRegression(random_state=random_state)
        model.fit(X_train, y_train)

        feature_importances += np.abs(model.coef_[0])

        y_pred = model.predict(X_test)
        y_pred_prob = model.predict_proba(X_test)[:, 1]

        auc = roc_auc_score(y_test, y_pred_prob)
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        mcc = compute_mcc(y_test, y_pred)

        metrics['auc'].append(auc)
        metrics['acc'].append(accuracy)
        metrics['prec'].append(precision)
        metrics['rec'].append(recall)
        metrics['f1'].append(f1)
        metrics['mcc'].append(mcc)

    # 結果
    res2 = make_result_df(metrics, 'Logistic Regression Normalized')

    feature_importances /= k
    feature_names = df.columns[:-1]
    sorted_idx = np.argsort(feature_importances)[-10:]
    sorted_importance = feature_importances[sorted_idx]
    sorted_features = feature_names[sorted_idx]

    plt.figure(figsize=(10, 8))
    plt.barh(sorted_features, sorted_importance, color='skyblue')
    plt.xlabel('Average Feature Importance')
    plt.title('Top 10 Feature Importances from k-foldCV of Logistic Regression normalized')
    plt.show()

    model_full = LogisticRegression(random_state=random_state)
    model_full.fit(X_scaled, y)
    os.makedirs(path_model, exist_ok=True)
    model_filename = os.path.join(path_model, 'kFCV_logistic_normalized.pkl')
    with open(model_filename, 'wb') as file:
        pickle.dump(model_full, file)

    return res2

##########################################
# Logistic Regression with Standardization
##########################################
def LogisticKFoldStandardized(k=k):
    from sklearn.linear_model import LogisticRegression
    from sklearn.preprocessing import StandardScaler

    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    scaler = StandardScaler()
    X_standardized = scaler.fit_transform(X)

    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)

    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }
    feature_importances = np.zeros((df.shape[1] - 1,))

    for train_index, test_index in kf.split(X_standardized):
        X_train, X_test = X_standardized[train_index], X_standardized[test_index]
        y_train, y_test = y[train_index], y[test_index]

        model = LogisticRegression(random_state=random_state)
        model.fit(X_train, y_train)

        feature_importances += np.abs(model.coef_[0])

        y_pred = model.predict(X_test)
        y_pred_prob = model.predict_proba(X_test)[:, 1]

        auc = roc_auc_score(y_test, y_pred_prob)
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        mcc = compute_mcc(y_test, y_pred)

        metrics['auc'].append(auc)
        metrics['acc'].append(accuracy)
        metrics['prec'].append(precision)
        metrics['rec'].append(recall)
        metrics['f1'].append(f1)
        metrics['mcc'].append(mcc)

    res2 = make_result_df(metrics, 'Logistic Regression Standardized')

    feature_importances /= k
    feature_names = df.columns[:-1]
    sorted_idx = np.argsort(feature_importances)[-10:]
    sorted_importance = feature_importances[sorted_idx]
    sorted_features = feature_names[sorted_idx]

    plt.figure(figsize=(10, 8))
    plt.barh(sorted_features, sorted_importance, color='skyblue')
    plt.xlabel('Average Feature Importance')
    plt.title('Top 10 Feature Importances from k-foldCV of Logistic Regression standardized')
    plt.show()

    model_full = LogisticRegression(random_state=random_state)
    model_full.fit(X_standardized, y)

    os.makedirs(path_model, exist_ok=True)
    model_filename = os.path.join(path_model, 'kFCV_logistic_standardized.pkl')
    with open(model_filename, 'wb') as file:
        pickle.dump(model_full, file)

    return res2

##########################################
# SVM Normalized
##########################################
def SVMKFoldNormalized(k=k):
    from sklearn.svm import SVC
    from sklearn.preprocessing import MinMaxScaler

    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)

    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)

    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }
    feature_importances = np.zeros((df.shape[1] - 1,))

    for train_index, test_index in kf.split(X_scaled):
        X_train, X_test = X_scaled[train_index], X_scaled[test_index]
        y_train, y_test = y[train_index], y[test_index]

        model = SVC(kernel='linear', probability=True, random_state=random_state)
        model.fit(X_train, y_train)

        if model.kernel == 'linear':
            feature_importances += np.abs(model.coef_[0])

        y_pred = model.predict(X_test)
        y_pred_prob = model.predict_proba(X_test)[:, 1]

        auc = roc_auc_score(y_test, y_pred_prob)
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        mcc = compute_mcc(y_test, y_pred)

        metrics['auc'].append(auc)
        metrics['acc'].append(accuracy)
        metrics['prec'].append(precision)
        metrics['rec'].append(recall)
        metrics['f1'].append(f1)
        metrics['mcc'].append(mcc)

    res2 = make_result_df(metrics, 'SVM Normalized')

    feature_importances /= k
    feature_names = df.columns[:-1]
    sorted_idx = np.argsort(feature_importances)[-10:]
    sorted_importance = feature_importances[sorted_idx]
    sorted_features = feature_names[sorted_idx]

    plt.figure(figsize=(10, 8))
    plt.barh(sorted_features, sorted_importance, color='skyblue')
    plt.xlabel('Average Feature Importance')
    plt.title('Top 10 Feature Importances from k-foldCV of linear SVM normalized')
    plt.show()
    print('')

    model_full = SVC(probability=True, random_state=random_state)
    model_full.fit(X_scaled, y)

    os.makedirs(path_model, exist_ok=True)
    model_filename = os.path.join(path_model, 'kFCV_svm_normalized.pkl')
    with open(model_filename, 'wb') as file:
        pickle.dump(model_full, file)

    return res2

##########################################
# SVM Standardized
##########################################
def SVMKFoldStandardized(k=k):
    from sklearn.svm import SVC
    from sklearn.preprocessing import StandardScaler

    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)

    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }
    feature_importances = np.zeros((X.shape[1],))

    for train_index, test_index in kf.split(X_scaled):
        X_train, X_test = X_scaled[train_index], X_scaled[test_index]
        y_train, y_test = y[train_index], y[test_index]

        model = SVC(kernel='linear', probability=True, random_state=random_state)
        model.fit(X_train, y_train)

        if model.kernel == 'linear':
            feature_importances += np.abs(model.coef_[0])

        y_pred = model.predict(X_test)
        y_pred_prob = model.predict_proba(X_test)[:, 1]

        auc = roc_auc_score(y_test, y_pred_prob)
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        mcc = compute_mcc(y_test, y_pred)

        metrics['auc'].append(auc)
        metrics['acc'].append(accuracy)
        metrics['prec'].append(precision)
        metrics['rec'].append(recall)
        metrics['f1'].append(f1)
        metrics['mcc'].append(mcc)

    res2 = make_result_df(metrics, 'SVM Standardized')

    feature_importances /= k
    feature_names = df.columns[:-1]
    sorted_idx = np.argsort(feature_importances)[-10:]
    sorted_importance = feature_importances[sorted_idx]
    sorted_features = feature_names[sorted_idx]

    plt.figure(figsize=(10, 8))
    plt.barh(sorted_features, sorted_importance, color='skyblue')
    plt.xlabel('Average Feature Importance')
    plt.title('Top 10 Feature Importances from k-foldCV of linear SVM standardized')
    plt.show()
    print('')

    model_full = SVC(probability=True, random_state=random_state)
    model_full.fit(X_scaled, y)

    os.makedirs(path_model, exist_ok=True)
    model_filename = os.path.join(path_model, 'kFCV_svm_standardized.pkl')
    with open(model_filename, 'wb') as file:
        pickle.dump(model_full, file)

    return res2

##########################################
# RandomForest
##########################################
def RandomForestKFold(k=k):
    from sklearn.ensemble import RandomForestClassifier

    X = df.iloc[:, :-1]
    y = df.iloc[:, -1].values

    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)

    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }
    feature_importance_list = []

    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y[train_index], y[test_index]

        model = RandomForestClassifier(random_state=random_state)
        model.fit(X_train, y_train)

        feature_importances = model.feature_importances_
        feature_importance_list.append(feature_importances)

        y_pred = model.predict(X_test)
        y_pred_prob = model.predict_proba(X_test)[:, 1]

        auc_ = roc_auc_score(y_test, y_pred_prob)
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred)
        f1_ = f1_score(y_test, y_pred)
        mcc = compute_mcc(y_test, y_pred)

        metrics['auc'].append(auc_)
        metrics['acc'].append(accuracy)
        metrics['prec'].append(precision)
        metrics['rec'].append(recall)
        metrics['f1'].append(f1_)
        metrics['mcc'].append(mcc)

    mean_feature_importances = np.mean(feature_importance_list, axis=0)
    indices = np.argsort(mean_feature_importances)[-10:]
    top_features = X.columns[indices]
    top_importances = mean_feature_importances[indices]

    # 結果表示・DataFrame
    res2 = make_result_df(metrics, 'RandomForest')

    plt.figure(figsize=(10, 6))
    plt.barh(range(len(indices)), top_importances, color='b', align='center')
    plt.yticks(range(len(indices)), [X.columns[i] for i in indices])
    plt.xlabel('Relative Importance')
    plt.title('Top 10 Feature Importances from Random Forest Model')
    plt.gca().invert_yaxis()
    plt.show()

    model_full = RandomForestClassifier(random_state=random_state)
    model_full.fit(X, y)

    os.makedirs(path_model, exist_ok=True)
    model_filename = os.path.join(path_model, 'kFCV_random_forest.pkl')
    with open(model_filename, 'wb') as file:
        pickle.dump(model_full, file)

    return res2

##########################################
# XGBoost (Default parameters)
##########################################
def XGBoostKFold(k=k):
    from xgboost import XGBClassifier
    import matplotlib.pyplot as plt

    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values
    feature_names = df.columns[:-1]

    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)

    # 全Foldの結果を格納する辞書
    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }
    feature_importance_list = []

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        # モデルの初期化 (Default)
        model = XGBClassifier(
            booster='gblinear',  # 一般的な性能のためgbtreeを推奨。gblinearにする場合は適宜変更
            use_label_encoder=False,
            eval_metric='logloss',
            random_state=random_state
        )
        model.fit(X_train, y_train)

        # 予測
        y_pred = model.predict(X_test)
        y_pred_prob = model.predict_proba(X_test)[:, 1]

        # スコア計算
        metrics['auc'].append(roc_auc_score(y_test, y_pred_prob))
        metrics['acc'].append(accuracy_score(y_test, y_pred))
        metrics['prec'].append(precision_score(y_test, y_pred, zero_division=0))
        metrics['rec'].append(recall_score(y_test, y_pred))
        metrics['f1'].append(f1_score(y_test, y_pred))
        metrics['mcc'].append(matthews_corrcoef(y_test, y_pred))

        # 重要度の保存
        feature_importance_list.append(model.feature_importances_)

    # 特徴重要度の可視化
    avg_importance = np.mean(feature_importance_list, axis=0)
    sorted_idx = np.argsort(avg_importance)[-10:]

    plt.figure(figsize=(10, 8))
    plt.barh(feature_names[sorted_idx], avg_importance[sorted_idx], color='skyblue')
    plt.xlabel("Average Importance")
    plt.title(f"Top 10 Feature Importances (Average) from XGBoost (Default)")
    plt.gca().invert_yaxis()
    plt.show()

    # フルデータで学習して保存
    model_full = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=random_state)
    model_full.fit(X, y)
    os.makedirs(path_model, exist_ok=True)
    with open(os.path.join(path_model, 'kFCV_xgboost_default.pkl'), 'wb') as f:
        pickle.dump(model_full, f)

    # 結果をDataFrame化
    return make_result_df(metrics, 'XGBoost (Default)')


##########################################
# XGBoost Optimized with Optuna
##########################################
def XGBoostOptunaKFold(k=k):
    import xgboost as xgb
    import optuna

    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values
    feature_names = df.columns[:-1]

    def objective(trial):
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'max_depth': trial.suggest_int('max_depth', 3, 9),
            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
        }

        model = xgb.XGBClassifier(
            **params,
            booster='gblinear',
            use_label_encoder=False,
            eval_metric='logloss',
            random_state=random_state
        )

        kf_opt = KFold(n_splits=k, shuffle=True, random_state=random_state)
        # 最適化の指標としてAUCの平均を使用
        auc_scores = cross_val_score(model, X, y, cv=kf_opt, scoring='roc_auc')
        return np.mean(auc_scores)

    # 最適化の実行
    study = optuna.create_study(direction='maximize')
    optuna.logging.disable_default_handler()
    study.optimize(objective, n_trials=n_trialsC)

    print(f"\n◆ Best hyperparameters for XGBoost: {study.best_params}")

    # 最良のパラメータで各Foldを再評価
    kf_final = KFold(n_splits=k, shuffle=True, random_state=random_state)
    metrics = {
        'auc': [],
        'acc': [],
        'prec': [],
        'rec': [],
        'f1': [],
        'mcc': []
    }
    feature_importance_list = []

    for train_index, test_index in kf_final.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        best_model = xgb.XGBClassifier(
            **study.best_params,
            use_label_encoder=False,
            eval_metric='logloss',
            random_state=random_state
        )
        best_model.fit(X_train, y_train)

        y_pred = best_model.predict(X_test)
        y_pred_prob = best_model.predict_proba(X_test)[:, 1]

        metrics['auc'].append(roc_auc_score(y_test, y_pred_prob))
        metrics['acc'].append(accuracy_score(y_test, y_pred))
        metrics['prec'].append(precision_score(y_test, y_pred, zero_division=0))
        metrics['rec'].append(recall_score(y_test, y_pred))
        metrics['f1'].append(f1_score(y_test, y_pred))
        metrics['mcc'].append(matthews_corrcoef(y_test, y_pred))

        feature_importance_list.append(best_model.feature_importances_)

    # 特徴重要度の可視化
    avg_importance = np.mean(feature_importance_list, axis=0)
    sorted_idx = np.argsort(avg_importance)[-10:]

    plt.figure(figsize=(10, 8))
    plt.barh(feature_names[sorted_idx], avg_importance[sorted_idx], color='lightcoral')
    plt.xlabel("Average Importance")
    plt.title(f"Top 10 Feature Importances (Average) from XGBoost (Optuna)")
    plt.gca().invert_yaxis()
    plt.show()

    # フルデータで学習して保存
    model_full = xgb.XGBClassifier(**study.best_params, use_label_encoder=False, eval_metric='logloss', random_state=random_state)
    model_full.fit(X, y)
    os.makedirs(path_model, exist_ok=True)
    with open(os.path.join(path_model, 'kFCV_xgboost_optuna.pkl'), 'wb') as f:
        pickle.dump(model_full, f)

    return make_result_df(metrics, 'XGBoost (Optuna)')

##########################################
# 実行パート
##########################################

print('')
res_linear = LinearKFold(k=k)
#print('')
#res_lasso = LassoKFold(alpha_value=0.2095426564930675, k=k)
print('')
res_ridge = RidgeKFoldOptuna(k=k)
print('')
res_logistic_N = LogisticKFoldNormalized(k=k)
print('')
res_logistic_S = LogisticKFoldStandardized(k=k)
print('')
res_SVM_N = SVMKFoldNormalized(k=k)
print('')
res_SVM_S = SVMKFoldStandardized(k=k)
print('')
res_XGBoost = XGBoostOptunaKFold(k=k)
print('')

# 各結果をまとめる
results = pd.concat([
    res_linear,
#    res_lasso,
    res_ridge,
    res_logistic_N,
    res_logistic_S,
    res_SVM_N,
    res_SVM_S,
#    res_RandomForest,
    res_XGBoost
], axis=0)

# まとめて出力
results.to_excel(filepath3)

